{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/qbs/anaconda3/lib/python3.10/site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/qbs/anaconda3/lib/python3.10/site-packages (4.12.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/qbs/anaconda3/lib/python3.10/site-packages (from requests) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/qbs/anaconda3/lib/python3.10/site-packages (from requests) (1.26.18)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/qbs/anaconda3/lib/python3.10/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/qbs/anaconda3/lib/python3.10/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/qbs/anaconda3/lib/python3.10/site-packages (from beautifulsoup4) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-api-python-client pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "\n",
    "# YouTube API credentials\n",
    "API_KEY = \"9f00f3ic0wg3rg\"  # Replace with your API key\n",
    "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
    "YOUTUBE_API_VERSION = \"v3\"\n",
    "\n",
    "# Search parameters\n",
    "QUERY = \"ELSA Speak: English Learning\"  # Search term\n",
    "MAX_RESULTS = 10  # Number of videos to retrieve\n",
    "\n",
    "# Initialize YouTube API client\n",
    "youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=API_KEY)\n",
    "\n",
    "def get_video_ids(query, max_results):\n",
    "    \"\"\"\n",
    "    Search YouTube videos based on a query and return their video IDs.\n",
    "\n",
    "    Args:\n",
    "        query (str): Search query for YouTube videos.\n",
    "        max_results (int): Maximum number of videos to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of video IDs.\n",
    "    \"\"\"\n",
    "    search_response = youtube.search().list(\n",
    "        q=query,\n",
    "        part=\"id,snippet\",\n",
    "        maxResults=max_results,\n",
    "        type=\"video\"\n",
    "    ).execute()\n",
    "\n",
    "    video_ids = [item[\"id\"][\"videoId\"] for item in search_response.get(\"items\", [])]\n",
    "    return video_ids\n",
    "\n",
    "def get_comments(video_id):\n",
    "    \"\"\"\n",
    "    Retrieve comments for a given video.\n",
    "\n",
    "    Args:\n",
    "        video_id (str): YouTube video ID.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: List of comments and their metadata.\n",
    "    \"\"\"\n",
    "    comments = []\n",
    "    try:\n",
    "        # Get comments from YouTube API\n",
    "        response = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            maxResults=100\n",
    "        ).execute()\n",
    "\n",
    "        for item in response.get(\"items\", []):\n",
    "            comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
    "            comments.append({\n",
    "                \"VideoID\": video_id,\n",
    "                \"Author\": comment[\"authorDisplayName\"],\n",
    "                \"Comment\": comment[\"textDisplay\"],\n",
    "                \"Likes\": comment[\"likeCount\"],\n",
    "                \"PublishedAt\": comment[\"publishedAt\"]\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving comments for video {video_id}: {e}\")\n",
    "\n",
    "    return comments\n",
    "\n",
    "def main():\n",
    "    # Step 1: Get video IDs related to the query\n",
    "    video_ids = get_video_ids(QUERY, MAX_RESULTS)\n",
    "    print(f\"Found {len(video_ids)} videos for query: '{QUERY}'\")\n",
    "\n",
    "    # Step 2: Retrieve comments for each video\n",
    "    all_comments = []\n",
    "    for video_id in video_ids:\n",
    "        print(f\"Fetching comments for video: {video_id}\")\n",
    "        comments = get_comments(video_id)\n",
    "        all_comments.extend(comments)\n",
    "\n",
    "    # Step 3: Save comments to a CSV file\n",
    "    if all_comments:\n",
    "        df = pd.DataFrame(all_comments)\n",
    "        df.to_csv(\"youtube_comments.csv\", index=False)\n",
    "        print(\"Comments saved to 'youtube_comments.csv'\")\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(\"No comments found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
